{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cv2 as cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预先写几个方法\n",
    "# 方法一就是获取文件夹下的数据\n",
    "def get_imgs(rate = 0.2):\n",
    "    \"\"\"\n",
    "    获取图片，并划分训练集和测试集\n",
    "    Parameters:\n",
    "        rate:测试集 2 和训练集 10 的比例，即测试集个数/训练集个数\n",
    "    Returns:\n",
    "        test_imgs:测试集\n",
    "        test_labels:测试集标签\n",
    "        train_imgs:训练集\n",
    "        train_labels:训练集标签\n",
    "    \"\"\"\n",
    "    # 读取图片\n",
    "    imgs = os.listdir('./verify/')\n",
    "    # 打乱图片顺序\n",
    "    random.shuffle(imgs)\n",
    "\n",
    "    # 数据集总共个数\n",
    "    imgs_num = len(imgs)\n",
    "    \n",
    "    # 按照比例求出测试集个数\n",
    "    test_num = int(imgs_num * rate / (1 + rate))\n",
    "    \n",
    "    # 测试集，测试数据的路径\n",
    "    test_imgs = imgs[:test_num]\n",
    "    # 根据文件名获取测试集标签\n",
    "    test_labels = list(map(lambda x: x.split('.')[0], test_imgs))\n",
    "    \n",
    "    \n",
    "    # 训练集\n",
    "    train_imgs = imgs[test_num:]\n",
    "    # 根据文件名获取训练集标签\n",
    "    train_labels = list(map(lambda x: x.split('.')[0], train_imgs))\n",
    "\n",
    "    return test_imgs, test_labels, train_imgs, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text2vec(text):\n",
    "    char_set_len = 63\n",
    "    \"\"\"\n",
    "    文本转向量\n",
    "    Parameters:\n",
    "        text:文本\n",
    "    Returns:\n",
    "        vector:向量\n",
    "    \"\"\"\n",
    "    if len(text) > 4:\n",
    "        raise ValueError('验证码最长4个字符')\n",
    "\n",
    "    vector = np.zeros(4 * char_set_len)\n",
    "    def char2pos(c):\n",
    "        if c =='_':\n",
    "            k = 62\n",
    "            return k\n",
    "        k = ord(c) - 48\n",
    "        if k > 9:\n",
    "            k = ord(c) - 55\n",
    "            if k > 35:\n",
    "                k = ord(c) - 61\n",
    "                if k > 61:\n",
    "                    raise ValueError('No Map')\n",
    "        return k\n",
    "    for i, c in enumerate(text):\n",
    "        idx = i * char_set_len + char2pos(c)\n",
    "        vector[idx] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义了每次取出一批数据，tensorflow训练的时候，一批批喂给算法，for循环执行很多次\n",
    "def get_next_batch(test_imgs,test_labels,train_imgs,train_labels,train_flag=True, batch_size=100):\n",
    "    train_size = 4160\n",
    "    test_size = 831\n",
    "    train_ptr = 0\n",
    "    test_ptr = 0\n",
    "    height = 30\n",
    "    width = 100\n",
    "    max_captcha = 4\n",
    "    # 0~ 9（10），a~z（26） ，A~Z（26） --------> 62 + 1 (_未知) -----> 63\n",
    "    char_set_len = 63\n",
    "    data_path = './verify/'\n",
    "    \"\"\"\n",
    "    获得batch_size大小的数据集\n",
    "    Parameters:\n",
    "        batch_size:batch_size大小\n",
    "        train_flag:是否从训练集获取数据\n",
    "    Returns:\n",
    "        batch_x:大小为batch_size的数据x\n",
    "        batch_y:大小为batch_size的数据y\n",
    "        image(用于测试)\n",
    "    \"\"\"\n",
    "    # 从训练集获取数据\n",
    "    if train_flag == True:\n",
    "        if (batch_size + train_ptr) < train_size:\n",
    "            trains = train_imgs[train_ptr:(train_ptr + batch_size)]\n",
    "            labels = train_labels[train_ptr:(train_ptr + batch_size)]\n",
    "            train_ptr += batch_size\n",
    "        else:\n",
    "            new_ptr = (train_ptr + batch_size) % train_size\n",
    "            trains = train_imgs[train_ptr:] + train_imgs[:new_ptr]\n",
    "            labels = train_labels[train_ptr:] + train_labels[:new_ptr]\n",
    "            train_ptr = new_ptr\n",
    "\n",
    "#       返回数据，给了形状\n",
    "        batch_X = np.zeros([batch_size, height*width])\n",
    "#       目标值，独热编码表示 4 * 63 ------> 概率问题\n",
    "        batch_y = np.zeros([batch_size, max_captcha*char_set_len])\n",
    "\n",
    "        for index, train in enumerate(trains):\n",
    "            # 黑白图片\n",
    "            img = np.mean(cv2.imread(data_path + train), axis = -1)\n",
    "            # 将多维降维1维\n",
    "            batch_X[index,:] = img.flatten() / 255\n",
    "        for index, label in enumerate(labels):\n",
    "            batch_y[index,:] = text2vec(label)\n",
    "\n",
    "    # 从测试集获取数据\n",
    "    else:\n",
    "        if (batch_size + test_ptr) < test_size:\n",
    "            tests = test_imgs[test_ptr:(test_ptr + batch_size)]\n",
    "            labels = test_labels[test_ptr:(test_ptr + batch_size)]\n",
    "            test_ptr += batch_size\n",
    "        else:\n",
    "            new_ptr = (test_ptr + batch_size) % test_size\n",
    "            tests = test_imgs[test_ptr:] + test_imgs[:new_ptr]\n",
    "            labels = test_labels[test_ptr:] + test_labels[:new_ptr]\n",
    "            test_ptr = new_ptr\n",
    "\n",
    "        batch_X = np.zeros([batch_size, height*width])\n",
    "        batch_y = np.zeros([batch_size, max_captcha*char_set_len])\n",
    "\n",
    "        for index, test in enumerate(tests):\n",
    "#             图片灰度化处理，黑白处理\n",
    "            img = np.mean(cv2.imread(data_path + test), axis = -1)\n",
    "            # 将多维降维1维\n",
    "            batch_X[index,:] = img.ravel() / 255\n",
    "        for index, label in enumerate(labels):\n",
    "            batch_y[index,:] = text2vec(label)\n",
    "        return batch_X, batch_y\n",
    "    return batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2text(vec):\n",
    "    char_set_len = 63\n",
    "    \"\"\"\n",
    "    向量转文本\n",
    "    Parameters:\n",
    "        vec:向量\n",
    "    Returns:\n",
    "        文本\n",
    "    \"\"\"\n",
    "    char_pos = vec.nonzero()[0]\n",
    "    text = []\n",
    "    for c in char_pos:\n",
    "        char_idx = c % char_set_len\n",
    "        if char_idx < 10:\n",
    "            char_code = char_idx + ord('0')\n",
    "        elif char_idx < 36:\n",
    "            char_code = char_idx - 10 + ord('A')\n",
    "        elif char_idx < 62:\n",
    "            char_code = char_idx - 36 + ord('a')\n",
    "        elif char_idx == 62:\n",
    "            char_code = ord('_')\n",
    "        else:\n",
    "            raise ValueError('error')\n",
    "        text.append(chr(char_code))\n",
    "    return \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, test_labels, train_imgs, train_labels=get_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['67go', 'p7fk', 'q4n8', 'st1l', 'y7zd', 'xgkk', 'ku1n', 'k9s2',\n",
       "       'bfug', '4gxe', '8lxy', 'u79s', 'tope', 'ntc1', '5do7', 'qths',\n",
       "       'lpzn', '5dsi', '466c', '6nt0', 'xef1', 'nupp', '793d', '5dj3',\n",
       "       '2ohi', 'ijgp', 'o0pu', 'avf0', 'ev0w', 'ik57', 'in1n', 'pcon',\n",
       "       'lobs', 'alt1', 'cequ', '4im4', 'zpv1', 'iemp', '8w7d', 'pt1a',\n",
       "       '84a3', 'dx7n', 'q3d9', '2vf6', '26jc', 'a9oe', '81pi', 'hdvh',\n",
       "       'pzwi', 'w0lj', 'mr6a', 'a86p', 'p7u6', 'm6i9', 'tkxk', '9p3o',\n",
       "       '9xrc', '4adf', 'c9rw', 'nard', '60zs', 'sk6y', '67yi', 'ahmx',\n",
       "       '3wy6', 'dja7', 'mvy1', '1m7l', '5iwd', '6hb3', '6e30', '0f5z',\n",
       "       '1kmd', 'cqoc', '5ayl', 'zm3e', 'su0u', 'zyr8', 'spem', 'jo7m',\n",
       "       '3234', '6woe', 'j0gg', 'yn26', 'trzl', 'dain', 'wsyc', '067z',\n",
       "       'ar79', 'ue3c', 'fx3q', 'y8ps', '5et6', '5yju', '96vl', 'hbof',\n",
       "       'cts9', 'q3n3', '0d7n', '381l', 'yrfc', 'l1g2', 'kbj0', '20dl',\n",
       "       'at6k', 'yocl', 'afpg', 'ghf2', 'go1b', '0hun', 'ruyp', '714d',\n",
       "       '5dwv', 'hia0', 'fwgy', 'djmb', 'oqyc', 'bp2n', 'pa0i', 'xzcv',\n",
       "       'mdez', 'efif', '61av', 'z8ke', 'qcuq', '1g6z', 'ti75', 'rli2',\n",
       "       'min5', 'nldy', 'l25r', '9ldg', 'ei56', 'ncv9', 'dfh5', '46og',\n",
       "       'ai4n', 'q670', 'mk7o', 'lmnp', 'n25t', 'tulc', 'nc1d', 'a6x5',\n",
       "       'xjau', 'cldw', 'gzp0', '7vi7', 'bcd1', 'bsca', '4j2a', 'd5j1',\n",
       "       'x9ad', 'bwk1', '86v9', '6fj0', 'w253', 'lymf', '3ime', 'kiap',\n",
       "       'lqtw', 'xc0f', 'zhz5', 'y6ei', 'g6za', '5svt', 'fzzf', 'err0',\n",
       "       '870m', '65zr', '3hft', 'i774', '0kpq', 'zyq8', 'rf0b', 'pr8z',\n",
       "       '510r', '7r1t', 'vsm2', 's6jv', 's11o', 'jn5b', 'solt', 'fctr',\n",
       "       'n2up', '4a87', 'bp7v', 'mnwl', 'gwhc', 'wr2r', '27ty', 'gmyf',\n",
       "       'f7y4', 'gm97', '8gz7', 'xaw3', 'oey9', 'pqzy', 'jcfd', '0b11',\n",
       "       's7g0', 'bdft', 'xlvq', '82sw', 'qf3r', 'alc8', 'eaya', '015k',\n",
       "       'rq45', 'yiyk', '316r', '94n0', '3tfn', 'eaez', '2azl', 'lpqn',\n",
       "       'bcrx', 'viw2', 'xs7l', 'zv69', '2b54', 'mwjv', 'tptt', 'tux4',\n",
       "       'yi62', 'yr2y', 't1mp', '89er', 'etzd', '02wx', '8upb', '0dk3',\n",
       "       '6qrc', 'owl2', 'plu1', 'o99q', 'jkl1', 'kim6', 'efv8', 'cw2l',\n",
       "       '9esu', 'aac8', 'yzjt', 'vnao', 'xqo7', 'fyh0', 'y8bc', '4iyw',\n",
       "       'azzu', 'd7xs', '9pls', 'jwg3', '99zm', '3901', 'tcjb', 'urek',\n",
       "       'ttgf', 'ywmx', 'vxa7', 'u0t2', 'j739', '7q6f', 'amm4', '72xs',\n",
       "       'zs9u', 'h527', '2cy2', 't0r6', 'fr2x', '1foo', '3xmr', 'g4qi',\n",
       "       '6qfx', 'pvpk', 'esq0', '2t39', '10n4', 'wac8', '9qjf', 'bmeb',\n",
       "       '5zci', 'lxtb', 'ulz6', 'v4ty', 'joiz', 'rzef', 'g13k', '51jw',\n",
       "       '2jw7', 'e8w6', '4tzg', '2irw', 'fch3', '0oh4', 'hawn', '0a5a',\n",
       "       's1s3', '1db9', 'ksww', 'tsmt', '970p', '1iz1', '24n5', 'mszt',\n",
       "       'cj2d', 'osdu', 'q06u', '8iv3', 'krmq', 'ae18', 'g1by', 'kiw4',\n",
       "       'jdhg', '3bjj', '42kv', 'tijd', 'anx9', 'qahb', 'cbmx', 'zu1o',\n",
       "       '9ai8', 'ao0t', 'fipx', 'uudr', 'm9xw', 'tiba', 'trp0', 'bv8z',\n",
       "       'ptp3', '5ztk', '7n6q', 'yovg', 'bert', 'cziw', 'xbxq', '643m',\n",
       "       'srd6', 'a95e', 'afi9', 'ygeo', 'hqxf', 'zpfc', '242d', '042t',\n",
       "       '7g67', 'o8t4', '5wvj', 'bk1w', 'w2ba', '3lq0', 'bry3', 'v9eo',\n",
       "       'kk4i', 'ecj9', 'kxfa', 'mlnm', 'i6hi', '21p8', 'mwaa', 'glye',\n",
       "       '0086', 'gric', 'bsyj', 'w4b9', 'hojr', 'o17o', 'hb24', '76ta',\n",
       "       'p83r', 'cy0a', 'ih5c', '312d', 'xnzx', '9crd', 't8a7', 'ah63',\n",
       "       '1r8u', 'l4xy', 'v6wu', 'sfo8', 'cr6y', 'mjzn', '9qxp', 'y9we',\n",
       "       'fv3z', 'psok', 'x4tj', 'zy1p', '0s0h', 'iwgp', 'fg5y', 'ob04',\n",
       "       'yjh9', 'j3sv', '3pp6', 'xsrf', 'v12e', 'hwgz', '2zeb', 'i8hq',\n",
       "       'qf58', '3c39', '33bx', 'o6t9', 'p1t9', '7i6b', 'j0ni', 'ogxc',\n",
       "       'sp6j', '2pu8', '91kx', 'nsp8', 's31s', 'rqp9', 'o9vd', 'bqkl',\n",
       "       'zel3', 'biih', '0358', 'wppi', '6swr', 'jcns', '3dss', '53p1',\n",
       "       'e3vd', 'mxgr', 'ybjf', 'nx8w', 'pw54', 'apkd', '0294', '9qzt',\n",
       "       'utra', '4wdp', 'z141', '0ww2', 'w6yu', 'sofp', 'li41', 'mem8',\n",
       "       '7ge8', 'lpk2', '2fee', 'giij', 'bey9', 'jz17', 's72e', 'k41y',\n",
       "       'c5co', '7tpi', 'lpkv', '7tv6', '5h8x', '79sn', 'mzdn', '9d63',\n",
       "       'uo76', '9kvf', 'rfw3', 'lp2i', 'glib', 'd8g6', 'l7c8', '42ge',\n",
       "       'visq', '9aef', 'gs6m', 'jb9j', '27cw', 'bj6p', 'latn', '2eto',\n",
       "       'p9sr', 'j82n', '6vgh', 'ejc7', '0d8d', 'b59b', 'amaq', '8te4',\n",
       "       '55hf', 'mqtp', 'xjw5', 'ygqk', 'gwkg', 'kahm', 'cnd0', 'z51q',\n",
       "       '7e9j', 'hm0y', 'lot8', 'eov4', 'm8nc', 'i550', 'kbeb', '8dmf',\n",
       "       'bpsk', 'v76q', 'dihp', 'rm8d', '1o24', 'jmrj', 'ua8m', '5p9h',\n",
       "       'ml2f', 'z4nd', 'dk3k', 'e4km', 'riz2', 'sxjn', 'zrc7', 'jr4m',\n",
       "       'rww9', 'phse', 'rfjm', 'ul8a', '6mjo', 'yj8k', 'okpz', 'nbj5',\n",
       "       'zowg', 'rfuf', 'b299', 'w33t', 'tj0e', 'xyae', 'r009', 'z3k4',\n",
       "       'lfdj', 'fu08', 'e2pm', 'doam', 'zmdi', 'k3fl', 'g6ah', 'npgw',\n",
       "       '4qst', 'g9q2', 'cbfq', 'nzjt', 'yf26', 'hoqr', 'q52s', 'v17n',\n",
       "       's9z9', 'sxqe', 'o3r3', 'xaln', '8hpk', 'hls9', 'f69t', 'z7s5',\n",
       "       '2qy8', 'hzq6', 'cboy', 'xgip', 'rbj1', 'yaia', 'm3v0', 'n5jr',\n",
       "       '0nya', 'jiml', 'kcq4', 'sexc', 'c9xa', '2e0m', '52t8', 'bbqj',\n",
       "       '0vdo', 'qb3n', '1bop', 'ad69', '6lxm', 'ch1b', 'hjtq', 'cswp',\n",
       "       'zu6o', 'sasn', '11pv', '975f', 'fsvr', 'dl4n', 'dcse', 'ak8b',\n",
       "       'ydfs', '7hcz', '9us7', 'owek', '73uy', 'a4iv', '7h8a', 'icem',\n",
       "       'ww36', 'a4gy', 'um5y', 'jei4', 'imqa', 'vn21', 'ubly', 'cvm3',\n",
       "       'yse1', 'b6uh', '5gme', '886h', 'o9dk', 'iamx', 'hh7z', 'v40j',\n",
       "       'l9y7', '8wxt', 'k5e8', '1as4', 'vwoh', 'oh0h', '8um7', '63vv',\n",
       "       '4bl9', '37rj', 'u7ey', 'ansa', '595e', '4a9m', '8nh1', 'mcak',\n",
       "       'acws', '2ofo', 'yfve', 'zg6a', 'y7lg', 'z4j3', 'bfvf', 'kdxl',\n",
       "       'jquo', 'zt74', 'mkkn', 'az5m', 'qvag', 'ngv5', '75h3', '5269',\n",
       "       'a8wh', '3gxy', 's1kg', '09io', '7wvf', 'cnbe', 'ah65', 'lb11',\n",
       "       'bq2s', '60mr', 'nqw9', 'xe1q', 'x8oz', 'fnsi', 'apgc', 'xy6o',\n",
       "       'n8xq', 'pls9', 'uwr6', '41vd', 'nat7', 'ejaj', 'ronp', 't0ix',\n",
       "       'njbj', 'nqx3', 'or8u', '3xd1', 'l4s4', 'foks', '98y8', 'hf7p',\n",
       "       'g8uj', 'njau', '738v', '3kd7', 'wvg7', 'vwn5', '2ang', 'hhey',\n",
       "       'l48j', 'r3se', 'ucei', '3cy8', 'n4gf', '5snm', '5s0k', 'wqvm',\n",
       "       '9tfn', 'aans', 'qdtk', '2j3k', 'fjhz', '6652', '1kad', 'qxub',\n",
       "       'scpd', '0uu6', 'wv4z', 'w0l4', 'mevj', 'lqa6', 'uwl2', '3dd3',\n",
       "       'rdp4', 'rchs', 'bslg', '3wtv', '63mn', 'dfjl', 'baqi', 'j11b',\n",
       "       'eeoq', 'zawq', 'rmk0', 'zlvj', 'c27x', 'xr8v', 'xq0q', 'p38i',\n",
       "       '62u4', 'dh5n', 'kuzu', 'h2ly', 'o6k6', 'q1sf', 'p0vo', 'b9o1',\n",
       "       '2ufo', 'fkds', 'tfxz', 'm6d0', 'uvbz', 'z1dp', 'tj3o', '5ukp',\n",
       "       '91xh', '8vaj', 'rcgn', 'flxp', 't8d3', 'snwi', '9mcm', '3dkr',\n",
       "       'ahth', '00zq', '5jhp', 'ne4u', 'iy7y', 'w1wj', 'wg6g', '9ov4',\n",
       "       'qstx', 'w0ri', 'bfkc', 'ns66', 'j04d', 'bzqd', '4dhw', 'ivsv',\n",
       "       'gffd', '5f0c', 'x991', 'izmg', 'oyg2', '2kfy', 'v0l8', 'tt0s',\n",
       "       'i3nc', '1t09', 'fgch', '19h5', 'daic', 'n58l', 'vpue', 'ibqb',\n",
       "       '8uh8', '9by8', '0fzt', '9xea', 'bccd', '7ff8', 'gwze', '9pkn',\n",
       "       'xgrx', 'fh1n', 'wht3', 'sw7v', 'c8ar', '333l', '1gri', 'ow0c',\n",
       "       'yifo', 'q3d3', 'jm38', 'hxqz', '19g8', 'dsn8', 'uhsq', 'pwnx',\n",
       "       'hzm4', '6i3p', 'at3g', '9zuc', '414k', '2o5w', '7zi7', '8p9f',\n",
       "       '0ob1', 'nnlo', 'upjt', 'g1lm', 'j2c5', '2luv', 'vspj', '2wsp',\n",
       "       '25r5', 'zwjq', 'aitg', '7fvf', 'n71e', 'fu3v', 'nu2j', 'onki',\n",
       "       'hclr', 's801', '1kvy', '7tac', 'gqcm', 'aa33', '6e0p'],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 30\n",
    "width = 100\n",
    "max_captcha = 4\n",
    "char_set_len = 63\n",
    "x_test = np.zeros([np.array(test_imgs).shape[0], height*width])\n",
    "y_test = np.zeros([np.array(test_labels).shape[0], max_captcha*char_set_len])\n",
    "for index, train in enumerate(test_imgs):\n",
    "            # 黑白图片\n",
    "            img = np.mean(cv2.imread('./verify/' + train), axis = -1)\n",
    "            # 将多维降维1维\n",
    "            x_test[index,:] = img.flatten() / 255.0\n",
    "for index, label in enumerate(test_labels):\n",
    "            y_test[index,:] = text2vec(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 30\n",
    "width = 100\n",
    "max_captcha = 4\n",
    "char_set_len = 63\n",
    "x_train = np.zeros([np.array(train_imgs).shape[0], height*width])\n",
    "y_train = np.zeros([np.array(train_labels).shape[0], max_captcha*char_set_len])\n",
    "for index, train in enumerate(train_imgs):\n",
    "            # 黑白图片\n",
    "            img = np.mean(cv2.imread('./verify/' + train), axis = -1)\n",
    "            # 将多维降维1维\n",
    "            x_train[index,:] = img.flatten() / 255.0\n",
    "for index, label in enumerate(train_labels):\n",
    "            y_train[index,:] = text2vec(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(831, 3000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(831, 252)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.reshape(-1,30,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(831, 30, 100, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(-1,30,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4160, 30, 100, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 100, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "            # 卷积层1 32个 5*5*3的filter，strides=1  padding=same\n",
    "#             tf.keras.layers.Flatten(input_shape=(30, 100)),\n",
    "            # [None, 30 * 100]\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, input_shape=x_train[0].shape,kernel_size=3, strides=1, padding=\"same\",\n",
    "                data_format=\"channels_last\", activation=tf.nn.relu\n",
    "            ),\n",
    "            # 池化层1 2*2窗口  strides=2\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=2,\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            # 卷积层2 64个 5*5*32的filter，strides=1  padding=same\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=1, padding=\"same\",\n",
    "                data_format=\"channels_last\", activation=tf.nn.relu\n",
    "            ),\n",
    "\n",
    "            # 池化层2 2*2窗口  strides=2 [none 8 8 64]\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=2,\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "            # 全连接层神经网络\n",
    "            # [none 8 8 64] ----> [None,8*8*64]\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # 1024个神经元网络\n",
    "            tf.keras.layers.Dense(units=1024, activation=tf.nn.relu),\n",
    "            # 100个神经元网络\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "            tf.keras.layers.Dense(units=4*63, activation=tf.nn.softmax),\n",
    "\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4160, 30, 100, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4160 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1761: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "2 root error(s) found.\n  (0) Failed precondition: Error while reading resource variable conv2d_4/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/conv2d_4/kernel/class tensorflow::Var does not exist.\n\t [[{{node conv2d_4/Conv2D/ReadVariableOp}}]]\n\t [[dropout_4/cond/then/_30/dropout/random_uniform/RandomUniform/_181]]\n  (1) Failed precondition: Error while reading resource variable conv2d_4/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/conv2d_4/kernel/class tensorflow::Var does not exist.\n\t [[{{node conv2d_4/Conv2D/ReadVariableOp}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-1c3f4a206038>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m model.fit(x=x_train, y=y_train,\n\u001b[0m\u001b[0;32m      8\u001b[0m                        \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                        epochs=1)\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m     return func.fit(\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    645\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m     return fit_loop(\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3954\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3956\u001b[1;33m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[0;32m   3957\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[0;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[0;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: 2 root error(s) found.\n  (0) Failed precondition: Error while reading resource variable conv2d_4/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/conv2d_4/kernel/class tensorflow::Var does not exist.\n\t [[{{node conv2d_4/Conv2D/ReadVariableOp}}]]\n\t [[dropout_4/cond/then/_30/dropout/random_uniform/RandomUniform/_181]]\n  (1) Failed precondition: Error while reading resource variable conv2d_4/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/conv2d_4/kernel/class tensorflow::Var does not exist.\n\t [[{{node conv2d_4/Conv2D/ReadVariableOp}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "model.fit(x=x_train, y=y_train,\n",
    "                       batch_size=32,\n",
    "                       epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X =tf.compat.v1.placeholder(dtype=tf.float64,shape = [None,3000])\n",
    "\n",
    "# kp = tf.compat.v1.placeholder(dtype=tf.float64,shape = None)\n",
    "\n",
    "# # 独热编码，长度4（验证码长度）* 63（0~9，A~Z，a~z _ 63）\n",
    "# y = tf.compat.v1.placeholder(dtype=tf.float64,shape = [None,4*63])\n",
    "# def crack_captcha_cnn():\n",
    "    \n",
    "# #     第一层\n",
    "#     input_data = tf.reshape(X,shape = [-1,30,100,1])\n",
    "\n",
    "#     filter1 = tf.Variable(initial_value=tf.random.normal(shape = [3,3,1,32],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "#     b1 = tf.Variable(initial_value=tf.random.normal(shape = [32],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "#     conv1 = tf.nn.conv2d(input_data,filter1,strides=[1,1,1,1],padding='SAME') + b1\n",
    "    \n",
    "#     relu1 = tf.nn.relu(conv1)\n",
    "# #     池化\n",
    "#     pool1 = tf.nn.max_pool(relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "# #     pool1 -------> shape = [-1,15,50,32]\n",
    "# #     第二层\n",
    "#     filter2 = tf.Variable(initial_value=tf.random.normal(shape = [3,3,32,64],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "#     b2 = tf.Variable(initial_value=tf.random.normal(shape = [64],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "\n",
    "#     conv2 = tf.nn.conv2d(pool1,filter2,strides=[1,1,1,1],padding='SAME') + b2\n",
    "    \n",
    "# #     激活函数\n",
    "#     sigmoid2 = tf.nn.sigmoid(conv2)\n",
    "    \n",
    "# #     池化\n",
    "#     pool2 = tf.nn.max_pool(sigmoid2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "# #     pool2  --------> shape = [-1,8,25,64]\n",
    "# #     第三层\n",
    "#     filter3 = tf.Variable(initial_value=tf.random.normal(shape = [3,3,64,64],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "#     b3 = tf.Variable(initial_value=tf.random.normal(shape = [64],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "#     conv3 = tf.nn.conv2d(pool2,filter3,strides=[1,1,1,1],padding='SAME') + b3\n",
    "\n",
    "#     relu3 = tf.nn.relu(conv3)\n",
    "    \n",
    "#     pool3 = tf.nn.max_pool(relu3,ksize= [1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "# #     pool3  --------> shape = [-1,4,13,64]\n",
    "# #     全连接层 1024 个神经元\n",
    "#     dense = tf.reshape(pool3,shape = [-1,4*13*64])\n",
    "    \n",
    "#     conn_w = tf.Variable(tf.random.normal(shape = [4*13*64,1024],dtype = tf.float64,stddev = 0.01),dtype= tf.float64)\n",
    "    \n",
    "#     conn_b  = tf.Variable(tf.random.normal(shape = [1024],dtype = tf.float64,stddev = 0.01),dtype= tf.float64)\n",
    "    \n",
    "#     conn = tf.matmul(dense,conn_w) + conn_b\n",
    "# #     conn -------> shape = [-1,1024]\n",
    "#     conn_relu = tf.nn.relu(conn)\n",
    "    \n",
    "# #     dropout\n",
    "#     dropout = tf.nn.dropout(conn_relu,rate=kp)\n",
    "    \n",
    "# #     输出层 y进行对比\n",
    "#     out_w = tf.Variable(initial_value=tf.random.normal(shape = [1024,4*63],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "#     out_b = tf.Variable(initial_value=tf.random.normal(shape = [4*63],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "#     out = tf.matmul(dropout,out_w) + out_b\n",
    "    \n",
    "# #     out ----------> shape = [?,4*63]\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 训练\n",
    "# def train_crack_captcha_cnn():\n",
    "    \n",
    "    \n",
    "    \n",
    "#     out = crack_captcha_cnn()\n",
    "#     saver = tf.compat.v1.train.Saver()\n",
    "    \n",
    "# #     真实分布，y \n",
    "#     cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels= y,logits=out))\n",
    "    \n",
    "#     optimizer = tf.compat.v1.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    \n",
    "# #     计算准确率方法,概率\n",
    "#     prob_ = tf.nn.softmax(out)\n",
    "    \n",
    "#     accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(prob_,axis = -1),tf.argmax(y,axis = -1)),tf.float64))\n",
    "    \n",
    "    \n",
    "#     with tf.compat.v1.Session() as sess:\n",
    "        \n",
    "#         sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        \n",
    "#         test_imgs,test_labels,train_imgs,train_labels = get_imgs()\n",
    "        \n",
    "#         for i in range(100000):\n",
    "            \n",
    "#             if (i%500 == 0)&(i!=0):\n",
    "#                 test_imgs,test_labels,train_imgs,train_labels = get_imgs()\n",
    "            \n",
    "#             X_train,y_train = get_next_batch(test_imgs,test_labels,train_imgs,train_labels)\n",
    "            \n",
    "            \n",
    "#             optimizer_,cost_ = sess.run(fetches = [optimizer,cost],feed_dict = {X:X_train,y:y_train,kp:0.5})\n",
    "            \n",
    "#             if i%100 == 0:\n",
    "#                 X_test,y_test = get_next_batch(test_imgs,test_labels,train_imgs,train_labels,train_flag=False,batch_size=500)\n",
    "#                 score = sess.run(fetches = accuracy,feed_dict={X:X_test,y:y_test,kp:1})\n",
    "#                 print('算法执行次数：{}算法准确率：{}'.format(i,score))\n",
    "#                 if score >=0.96:\n",
    "#                     saver.save(sess,'./captcha/model',i)\n",
    "                    \n",
    "#             if (i%1000 == 0)&(i!=0):\n",
    "#                 saver.save(sess,'./captcha/model',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "2 root error(s) found.\n  (0) Not found: No algorithm worked!\n\t [[node Conv2D_3 (defined at <ipython-input-17-e56fe0ce0afb>:16) ]]\n  (1) Not found: No algorithm worked!\n\t [[node Conv2D_3 (defined at <ipython-input-17-e56fe0ce0afb>:16) ]]\n\t [[Mean_2/_9]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Conv2D_3:\n Reshape_2 (defined at <ipython-input-17-e56fe0ce0afb>:10)\n\nInput Source operations connected to node Conv2D_3:\n Reshape_2 (defined at <ipython-input-17-e56fe0ce0afb>:10)\n\nOriginal stack trace for 'Conv2D_3':\n  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 193, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n    super().run_forever()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 567, in run_forever\n    self._run_once()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1855, in _run_once\n    handle._run()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n    self.do_execute(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-6ea79fa8cbf0>\", line 1, in <module>\n    train_crack_captcha_cnn()\n  File \"<ipython-input-18-137e65b57150>\", line 6, in train_crack_captcha_cnn\n    out = crack_captcha_cnn()\n  File \"<ipython-input-17-e56fe0ce0afb>\", line 16, in crack_captcha_cnn\n    conv1 = tf.nn.conv2d(input_data,filter1,strides=[1,1,1,1],padding='SAME') + b1\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2163, in conv2d_v2\n    return conv2d(input,  # pylint: disable=redefined-builtin\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2270, in conv2d\n    return gen_nn_ops.conv2d(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 968, in conv2d\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1450\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1451\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: No algorithm worked!\n\t [[{{node Conv2D_3}}]]\n  (1) Not found: No algorithm worked!\n\t [[{{node Conv2D_3}}]]\n\t [[Mean_2/_9]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-6ea79fa8cbf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_crack_captcha_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-137e65b57150>\u001b[0m in \u001b[0;36mtrain_crack_captcha_cnn\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0moptimizer_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1369\u001b[0m                            run_metadata)\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1394\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: No algorithm worked!\n\t [[node Conv2D_3 (defined at <ipython-input-17-e56fe0ce0afb>:16) ]]\n  (1) Not found: No algorithm worked!\n\t [[node Conv2D_3 (defined at <ipython-input-17-e56fe0ce0afb>:16) ]]\n\t [[Mean_2/_9]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Conv2D_3:\n Reshape_2 (defined at <ipython-input-17-e56fe0ce0afb>:10)\n\nInput Source operations connected to node Conv2D_3:\n Reshape_2 (defined at <ipython-input-17-e56fe0ce0afb>:10)\n\nOriginal stack trace for 'Conv2D_3':\n  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 193, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n    super().run_forever()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 567, in run_forever\n    self._run_once()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1855, in _run_once\n    handle._run()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n    self.do_execute(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-6ea79fa8cbf0>\", line 1, in <module>\n    train_crack_captcha_cnn()\n  File \"<ipython-input-18-137e65b57150>\", line 6, in train_crack_captcha_cnn\n    out = crack_captcha_cnn()\n  File \"<ipython-input-17-e56fe0ce0afb>\", line 16, in crack_captcha_cnn\n    conv1 = tf.nn.conv2d(input_data,filter1,strides=[1,1,1,1],padding='SAME') + b1\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2163, in conv2d_v2\n    return conv2d(input,  # pylint: disable=redefined-builtin\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2270, in conv2d\n    return gen_nn_ops.conv2d(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 968, in conv2d\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# train_crack_captcha_cnn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
