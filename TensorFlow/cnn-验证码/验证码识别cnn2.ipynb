{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cv2 as cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预先写几个方法\n",
    "# 方法一就是获取文件夹下的数据\n",
    "def get_imgs(rate = 0.2):\n",
    "    \"\"\"\n",
    "    获取图片，并划分训练集和测试集\n",
    "    Parameters:\n",
    "        rate:测试集 2 和训练集 10 的比例，即测试集个数/训练集个数\n",
    "    Returns:\n",
    "        test_imgs:测试集\n",
    "        test_labels:测试集标签\n",
    "        train_imgs:训练集\n",
    "        train_labels:训练集标签\n",
    "    \"\"\"\n",
    "    # 读取图片\n",
    "    imgs = os.listdir('./verify/')\n",
    "    # 打乱图片顺序\n",
    "    random.shuffle(imgs)\n",
    "\n",
    "    # 数据集总共个数\n",
    "    imgs_num = len(imgs)\n",
    "    \n",
    "    # 按照比例求出测试集个数\n",
    "    test_num = int(imgs_num * rate / (1 + rate))\n",
    "    \n",
    "    # 测试集，测试数据的路径\n",
    "    test_imgs = imgs[:test_num]\n",
    "    # 根据文件名获取测试集标签\n",
    "    test_labels = list(map(lambda x: x.split('.')[0], test_imgs))\n",
    "    \n",
    "    \n",
    "    # 训练集\n",
    "    train_imgs = imgs[test_num:]\n",
    "    # 根据文件名获取训练集标签\n",
    "    train_labels = list(map(lambda x: x.split('.')[0], train_imgs))\n",
    "\n",
    "    return test_imgs, test_labels, train_imgs, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set_len = 63\n",
    "def text2vec(text):\n",
    "    \"\"\"\n",
    "    文本转向量\n",
    "    Parameters:\n",
    "        text:文本\n",
    "    Returns:\n",
    "        vector:向量\n",
    "    \"\"\"\n",
    "    if len(text) > 4:\n",
    "        raise ValueError('验证码最长4个字符')\n",
    "\n",
    "    vector = np.zeros(4 * char_set_len)\n",
    "    def char2pos(c):\n",
    "        if c =='_':\n",
    "            k = 62\n",
    "            return k\n",
    "        k = ord(c) - 48\n",
    "        if k > 9:\n",
    "            k = ord(c) - 55\n",
    "            if k > 35:\n",
    "                k = ord(c) - 61\n",
    "                if k > 61:\n",
    "                    raise ValueError('No Map')\n",
    "        return k\n",
    "    for i, c in enumerate(text):\n",
    "        idx = i * char_set_len + char2pos(c)\n",
    "        vector[idx] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义了每次取出一批数据，tensorflow训练的时候，一批批喂给算法，for循环执行很多次\n",
    "def get_next_batch(test_imgs,test_labels,train_imgs,train_labels,train_flag=True, batch_size=100):\n",
    "    train_size = 4160\n",
    "    test_size = 831\n",
    "    train_ptr = 0\n",
    "    test_ptr = 0\n",
    "    height = 30\n",
    "    width = 100\n",
    "    max_captcha = 4\n",
    "    # 0~ 9（10），a~z（26） ，A~Z（26） --------> 62 + 1 (_未知) -----> 63\n",
    "    char_set_len = 63\n",
    "    data_path = './verify/'\n",
    "    \"\"\"\n",
    "    获得batch_size大小的数据集\n",
    "    Parameters:\n",
    "        batch_size:batch_size大小\n",
    "        train_flag:是否从训练集获取数据\n",
    "    Returns:\n",
    "        batch_x:大小为batch_size的数据x\n",
    "        batch_y:大小为batch_size的数据y\n",
    "        image(用于测试)\n",
    "    \"\"\"\n",
    "    # 从训练集获取数据\n",
    "    if train_flag == True:\n",
    "        if (batch_size + train_ptr) < train_size:\n",
    "            trains = train_imgs[train_ptr:(train_ptr + batch_size)]\n",
    "            labels = train_labels[train_ptr:(train_ptr + batch_size)]\n",
    "            train_ptr += batch_size\n",
    "        else:\n",
    "            new_ptr = (train_ptr + batch_size) % train_size\n",
    "            trains = train_imgs[train_ptr:] + train_imgs[:new_ptr]\n",
    "            labels = train_labels[train_ptr:] + train_labels[:new_ptr]\n",
    "            train_ptr = new_ptr\n",
    "\n",
    "#       返回数据，给了形状\n",
    "        batch_X = np.zeros([batch_size, height*width])\n",
    "#       目标值，独热编码表示 4 * 63 ------> 概率问题\n",
    "        batch_y = np.zeros([batch_size, max_captcha*char_set_len])\n",
    "\n",
    "        for index, train in enumerate(trains):\n",
    "            # 黑白图片\n",
    "            img = np.mean(cv2.imread(data_path + train), axis = -1)\n",
    "            # 将多维降维1维\n",
    "            batch_X[index,:] = img.flatten() / 255\n",
    "        for index, label in enumerate(labels):\n",
    "            batch_y[index,:] = text2vec(label)\n",
    "\n",
    "    # 从测试集获取数据\n",
    "    else:\n",
    "        if (batch_size + test_ptr) < test_size:\n",
    "            tests = test_imgs[test_ptr:(test_ptr + batch_size)]\n",
    "            labels = test_labels[test_ptr:(test_ptr + batch_size)]\n",
    "            test_ptr += batch_size\n",
    "        else:\n",
    "            new_ptr = (test_ptr + batch_size) % test_size\n",
    "            tests = test_imgs[test_ptr:] + test_imgs[:new_ptr]\n",
    "            labels = test_labels[test_ptr:] + test_labels[:new_ptr]\n",
    "            test_ptr = new_ptr\n",
    "\n",
    "        batch_X = np.zeros([batch_size, height*width])\n",
    "        batch_y = np.zeros([batch_size, max_captcha*char_set_len])\n",
    "\n",
    "        for index, test in enumerate(tests):\n",
    "#             图片灰度化处理，黑白处理\n",
    "            img = np.mean(cv2.imread(data_path + test), axis = -1)\n",
    "            # 将多维降维1维\n",
    "            batch_X[index,:] = img.ravel() / 255\n",
    "        for index, label in enumerate(labels):\n",
    "            batch_y[index,:] = text2vec(label)\n",
    "        return batch_X, batch_y\n",
    "    return batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2text(vec):\n",
    "    char_set_len = 63\n",
    "    \"\"\"\n",
    "    向量转文本\n",
    "    Parameters:\n",
    "        vec:向量\n",
    "    Returns:\n",
    "        文本\n",
    "    \"\"\"\n",
    "    char_pos = vec.nonzero()[0]\n",
    "    text = []\n",
    "    for c in char_pos:\n",
    "        char_idx = c % char_set_len\n",
    "        if char_idx < 10:\n",
    "            char_code = char_idx + ord('0')\n",
    "        elif char_idx < 36:\n",
    "            char_code = char_idx - 10 + ord('A')\n",
    "        elif char_idx < 62:\n",
    "            char_code = char_idx - 36 + ord('a')\n",
    "        elif char_idx == 62:\n",
    "            char_code = ord('_')\n",
    "        else:\n",
    "            raise ValueError('error')\n",
    "        text.append(chr(char_code))\n",
    "    return \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =tf.compat.v1.placeholder(dtype=tf.float64,shape = [None,3000])\n",
    "\n",
    "kp = tf.compat.v1.placeholder(dtype=tf.float64,shape = None)\n",
    "\n",
    "# 独热编码，长度4（验证码长度）* 63（0~9，A~Z，a~z _ 63）\n",
    "y = tf.compat.v1.placeholder(dtype=tf.float64,shape = [None,4*63])\n",
    "def crack_captcha_cnn():\n",
    "    \n",
    "#     第一层\n",
    "    input_data = tf.reshape(X,shape = [-1,30,100,1])\n",
    "\n",
    "    filter1 = tf.Variable(initial_value=tf.random.normal(shape = [3,3,1,32],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "    b1 = tf.Variable(initial_value=tf.random.normal(shape = [32],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "    conv1 = tf.nn.conv2d(input_data,filter1,strides=[1,1,1,1],padding='SAME') + b1\n",
    "    \n",
    "    relu1 = tf.nn.relu(conv1)\n",
    "#     池化\n",
    "    pool1 = tf.nn.max_pool(relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "#     pool1 -------> shape = [-1,15,50,32]\n",
    "#     第二层\n",
    "    filter2 = tf.Variable(initial_value=tf.random.normal(shape = [3,3,32,64],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "    b2 = tf.Variable(initial_value=tf.random.normal(shape = [64],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "\n",
    "    conv2 = tf.nn.conv2d(pool1,filter2,strides=[1,1,1,1],padding='SAME') + b2\n",
    "    \n",
    "#     激活函数\n",
    "    sigmoid2 = tf.nn.sigmoid(conv2)\n",
    "    \n",
    "#     池化\n",
    "    pool2 = tf.nn.max_pool(sigmoid2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "#     pool2  --------> shape = [-1,8,25,64]\n",
    "#     第三层\n",
    "    filter3 = tf.Variable(initial_value=tf.random.normal(shape = [3,3,64,64],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "    b3 = tf.Variable(initial_value=tf.random.normal(shape = [64],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "    conv3 = tf.nn.conv2d(pool2,filter3,strides=[1,1,1,1],padding='SAME') + b3\n",
    "\n",
    "    relu3 = tf.nn.relu(conv3)\n",
    "    \n",
    "    pool3 = tf.nn.max_pool(relu3,ksize= [1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "#     pool3  --------> shape = [-1,4,13,64]\n",
    "#     全连接层 1024 个神经元\n",
    "    dense = tf.reshape(pool3,shape = [-1,4*13*64])\n",
    "    \n",
    "    conn_w = tf.Variable(tf.random.normal(shape = [4*13*64,1024],dtype = tf.float64,stddev = 0.01),dtype= tf.float64)\n",
    "    \n",
    "    conn_b  = tf.Variable(tf.random.normal(shape = [1024],dtype = tf.float64,stddev = 0.01),dtype= tf.float64)\n",
    "    \n",
    "    conn = tf.matmul(dense,conn_w) + conn_b\n",
    "#     conn -------> shape = [-1,1024]\n",
    "    conn_relu = tf.nn.relu(conn)\n",
    "    \n",
    "#     dropout\n",
    "    dropout = tf.nn.dropout(conn_relu,rate=kp)\n",
    "    \n",
    "#     输出层 y进行对比\n",
    "    out_w = tf.Variable(initial_value=tf.random.normal(shape = [1024,4*63],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    out_b = tf.Variable(initial_value=tf.random.normal(shape = [4*63],dtype = tf.float64,stddev = 0.01),dtype=tf.float64)\n",
    "    \n",
    "    out = tf.matmul(dropout,out_w) + out_b\n",
    "    \n",
    "#     out ----------> shape = [?,4*63]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "def train_crack_captcha_cnn():\n",
    "    \n",
    "    \n",
    "    \n",
    "    out = crack_captcha_cnn()\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    \n",
    "#     真实分布，y \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels= y,logits=out))\n",
    "    \n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    \n",
    "#     计算准确率方法,概率\n",
    "    prob_ = tf.nn.softmax(out)\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(prob_,axis = -1),tf.argmax(y,axis = -1)),tf.float64))\n",
    "    \n",
    "    \n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        \n",
    "        test_imgs,test_labels,train_imgs,train_labels = get_imgs()\n",
    "        \n",
    "        for i in range(100000):\n",
    "            \n",
    "            if (i%500 == 0)&(i!=0):\n",
    "                test_imgs,test_labels,train_imgs,train_labels = get_imgs()\n",
    "            \n",
    "            X_train,y_train = get_next_batch(test_imgs,test_labels,train_imgs,train_labels)\n",
    "            \n",
    "            \n",
    "            optimizer_,cost_ = sess.run(fetches = [optimizer,cost],feed_dict = {X:X_train,y:y_train,kp:0.5})\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                X_test,y_test = get_next_batch(test_imgs,test_labels,train_imgs,train_labels,train_flag=False,batch_size=500)\n",
    "                score = sess.run(fetches = accuracy,feed_dict={X:X_test,y:y_test,kp:1})\n",
    "                print('算法执行次数：{}算法准确率：{}'.format(i,score))\n",
    "                if score >=0.96:\n",
    "                    saver.save(sess,'./captcha/model',i)\n",
    "                    \n",
    "            if (i%1000 == 0)&(i!=0):\n",
    "                saver.save(sess,'./captcha/model',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "2 root error(s) found.\n  (0) Not found: No algorithm worked!\n\t [[node Conv2D_3 (defined at <ipython-input-17-e56fe0ce0afb>:16) ]]\n  (1) Not found: No algorithm worked!\n\t [[node Conv2D_3 (defined at <ipython-input-17-e56fe0ce0afb>:16) ]]\n\t [[Mean_2/_9]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Conv2D_3:\n Reshape_2 (defined at <ipython-input-17-e56fe0ce0afb>:10)\n\nInput Source operations connected to node Conv2D_3:\n Reshape_2 (defined at <ipython-input-17-e56fe0ce0afb>:10)\n\nOriginal stack trace for 'Conv2D_3':\n  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 193, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n    super().run_forever()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 567, in run_forever\n    self._run_once()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1855, in _run_once\n    handle._run()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n    self.do_execute(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-6ea79fa8cbf0>\", line 1, in <module>\n    train_crack_captcha_cnn()\n  File \"<ipython-input-18-137e65b57150>\", line 6, in train_crack_captcha_cnn\n    out = crack_captcha_cnn()\n  File \"<ipython-input-17-e56fe0ce0afb>\", line 16, in crack_captcha_cnn\n    conv1 = tf.nn.conv2d(input_data,filter1,strides=[1,1,1,1],padding='SAME') + b1\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2163, in conv2d_v2\n    return conv2d(input,  # pylint: disable=redefined-builtin\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2270, in conv2d\n    return gen_nn_ops.conv2d(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 968, in conv2d\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_do_call\u001B[1;34m(self, fn, *args)\u001B[0m\n\u001B[0;32m   1374\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1375\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1376\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOpError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_run_fn\u001B[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[0;32m   1358\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_extend_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1359\u001B[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001B[0m\u001B[0;32m   1360\u001B[0m                                       target_list, run_metadata)\n",
      "\u001B[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_call_tf_sessionrun\u001B[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[0;32m   1450\u001B[0m                           run_metadata):\n\u001B[1;32m-> 1451\u001B[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001B[0m\u001B[0;32m   1452\u001B[0m                                             \u001B[0mfetch_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget_list\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNotFoundError\u001B[0m: 2 root error(s) found.\n  (0) Not found: No algorithm worked!\n\t [[{{node Conv2D_3}}]]\n  (1) Not found: No algorithm worked!\n\t [[{{node Conv2D_3}}]]\n\t [[Mean_2/_9]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-19-6ea79fa8cbf0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrain_crack_captcha_cnn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-18-137e65b57150>\u001B[0m in \u001B[0;36mtrain_crack_captcha_cnn\u001B[1;34m()\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m             \u001B[0moptimizer_\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcost_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfetches\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcost\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mfeed_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mkp\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m0.5\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m%\u001B[0m\u001B[1;36m100\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m    965\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    966\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 967\u001B[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001B[0m\u001B[0;32m    968\u001B[0m                          run_metadata_ptr)\n\u001B[0;32m    969\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_run\u001B[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1188\u001B[0m     \u001B[1;31m# or if the call is a partial run that specifies feeds.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1189\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mfinal_fetches\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mfinal_targets\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mhandle\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mfeed_dict_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1190\u001B[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001B[0m\u001B[0;32m   1191\u001B[0m                              feed_dict_tensor, options, run_metadata)\n\u001B[0;32m   1192\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_do_run\u001B[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1366\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1367\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhandle\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1368\u001B[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001B[0m\u001B[0;32m   1369\u001B[0m                            run_metadata)\n\u001B[0;32m   1370\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_do_call\u001B[1;34m(self, fn, *args)\u001B[0m\n\u001B[0;32m   1392\u001B[0m                     \u001B[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1393\u001B[0m                     'disable_meta_optimizer = True')\n\u001B[1;32m-> 1394\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnode_def\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1395\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1396\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_extend_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNotFoundError\u001B[0m: 2 root error(s) found.\n  (0) Not found: No algorithm worked!\n\t [[node Conv2D_3 (defined at <ipython-input-17-e56fe0ce0afb>:16) ]]\n  (1) Not found: No algorithm worked!\n\t [[node Conv2D_3 (defined at <ipython-input-17-e56fe0ce0afb>:16) ]]\n\t [[Mean_2/_9]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Conv2D_3:\n Reshape_2 (defined at <ipython-input-17-e56fe0ce0afb>:10)\n\nInput Source operations connected to node Conv2D_3:\n Reshape_2 (defined at <ipython-input-17-e56fe0ce0afb>:10)\n\nOriginal stack trace for 'Conv2D_3':\n  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 193, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"D:\\Python\\Python38\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n    super().run_forever()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 567, in run_forever\n    self._run_once()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1855, in _run_once\n    handle._run()\n  File \"D:\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n    self.do_execute(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-6ea79fa8cbf0>\", line 1, in <module>\n    train_crack_captcha_cnn()\n  File \"<ipython-input-18-137e65b57150>\", line 6, in train_crack_captcha_cnn\n    out = crack_captcha_cnn()\n  File \"<ipython-input-17-e56fe0ce0afb>\", line 16, in crack_captcha_cnn\n    conv1 = tf.nn.conv2d(input_data,filter1,strides=[1,1,1,1],padding='SAME') + b1\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2163, in conv2d_v2\n    return conv2d(input,  # pylint: disable=redefined-builtin\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2270, in conv2d\n    return gen_nn_ops.conv2d(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 968, in conv2d\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"d:\\python\\venv(data_analysis)\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "train_crack_captcha_cnn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}